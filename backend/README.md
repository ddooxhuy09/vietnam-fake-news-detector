# Backend API Server

FastAPI server cung c·∫•p API ƒë·ªÉ ph√°t hi·ªán tin gi·∫£ tr√™n TikTok v·ªõi c√°c t√≠nh nƒÉng ML/AI ti√™n ti·∫øn v√† GPU acceleration.

## üìã T·ªïng quan

Backend n√†y cung c·∫•p:
- **Prediction API**: D·ª± ƒëo√°n tin gi·∫£/th·∫≠t t·ª´ video TikTok
- **Media Processing**: OCR v√† Speech-to-Text t·ª´ video v·ªõi GPU support
- **RAG Verification**: X√°c minh v·ªõi ngu·ªìn tin ƒë√°ng tin c·∫≠y
- **CUDA Detection**: T·ª± ƒë·ªông detect v√† s·ª≠ d·ª•ng GPU n·∫øu c√≥
- **Caching**: L∆∞u k·∫øt qu·∫£ ƒë·ªÉ t·ªëi ∆∞u performance
- **Reporting**: H·ªá th·ªëng b√°o c√°o ƒë·ªÉ c·∫£i thi·ªán model

## üèóÔ∏è Ki·∫øn tr√∫c

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   FastAPI    ‚îÇ
‚îÇ   (main.py)  ‚îÇ
‚îÇ  CUDA Detect ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
   ‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ       ‚îÇ
   ‚ñº       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇRouter‚îÇ ‚îÇ Services ‚îÇ
‚îÇ      ‚îÇ ‚îÇ  (GPU)   ‚îÇ
‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚îÇ          ‚îÇ
   ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ    ‚îÇ           ‚îÇ
   ‚ñº    ‚ñº           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇPred‚îÇ ‚îÇMed ‚îÇ ‚îÇ   RAG    ‚îÇ
‚îÇict ‚îÇ ‚îÇia  ‚îÇ ‚îÇ Service  ‚îÇ
‚îÇ    ‚îÇ ‚îÇ    ‚îÇ ‚îÇ  (GPU)   ‚îÇ
‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îò ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚îÇ      ‚îÇ         ‚îÇ
   ‚îÇ      ‚îÇ         ‚îÇ
   ‚ñº      ‚ñº         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇHAN   ‚îÇ ‚îÇOCR/  ‚îÇ ‚îÇ Supabase ‚îÇ
‚îÇModel ‚îÇ ‚îÇSTT   ‚îÇ ‚îÇ   DB     ‚îÇ
‚îÇ(GPU) ‚îÇ ‚îÇ(GPU) ‚îÇ ‚îÇ          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìÅ C·∫•u tr√∫c th∆∞ m·ª•c

```
backend/
‚îú‚îÄ‚îÄ main.py                 # FastAPI app entry point (CUDA detection)
‚îú‚îÄ‚îÄ requirement.txt          # Python dependencies
‚îÇ
‚îú‚îÄ‚îÄ routers/                # API endpoints
‚îÇ   ‚îú‚îÄ‚îÄ predict.py          # Prediction endpoint
‚îÇ   ‚îú‚îÄ‚îÄ media.py            # Media processing endpoint (smart routing)
‚îÇ   ‚îî‚îÄ‚îÄ reports.py          # Reporting endpoint
‚îÇ
‚îú‚îÄ‚îÄ services/               # Business logic (GPU-accelerated)
‚îÇ   ‚îú‚îÄ‚îÄ inference.py        # HAN model inference (ONNX + CUDA)
‚îÇ   ‚îú‚îÄ‚îÄ rag_service.py      # RAG verification (GPU)
‚îÇ   ‚îú‚îÄ‚îÄ media_processor.py  # Video/image processing (URL type detection)
‚îÇ   ‚îú‚îÄ‚îÄ ocr_service.py     # OCR service (GPU)
‚îÇ   ‚îú‚îÄ‚îÄ stt_service.py     # Speech-to-Text service (GPU)
‚îÇ   ‚îî‚îÄ‚îÄ supabase_client.py # Database client
‚îÇ
‚îî‚îÄ‚îÄ scripts/                # Utility scripts
    ‚îú‚îÄ‚îÄ generate_embeddings.py
    ‚îî‚îÄ‚îÄ regenerate_embeddings.py
```

## üöÄ C√†i ƒë·∫∑t

### 1. C√†i ƒë·∫∑t dependencies

```bash
pip install -r requirement.txt
```

**Key dependencies:**
- `fastapi`: Web framework
- `uvicorn`: ASGI server
- `onnxruntime-gpu`: Model inference v·ªõi CUDA support
- `sentence-transformers`: Embeddings (GPU)
- `supabase`: Database client
- `vietocr`: Vietnamese OCR (GPU)
- `openai-whisper`: Speech-to-Text (GPU)
- `yt-dlp`: Video download
- `opencv-python`: Image processing
- `moviepy`: Audio extraction
- `torch`: PyTorch cho CUDA detection

### 2. C·∫•u h√¨nh Environment Variables

T·∫°o file `.env`:

```env
# Supabase
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-service-role-key

# Model paths
MODEL_PATH=./models/han_rag_model.onnx
TOKENIZER_PATH=vinai/phobert-base-v2
EMBEDDING_MODEL=keepitreal/vietnamese-sbert

# Server
PORT=8000
HOST=0.0.0.0
```

### 3. Setup Database

Ch·∫°y SQL schema t·ª´ `extension/database/supabase_schema.sql` tr√™n Supabase.

### 4. Ch·∫°y server

```bash
python main.py
```

Server s·∫Ω t·ª± ƒë·ªông detect CUDA khi kh·ªüi ƒë·ªông:
```
‚úÖ CUDA Available: NVIDIA GeForce RTX 3050 Ti Laptop GPU
‚úÖ CUDA Version: 12.1
CUDA: ‚úÖ GPU
```

Ho·∫∑c v·ªõi uvicorn:
```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

Server s·∫Ω ch·∫°y t·∫°i: `http://localhost:8000`

API docs: `http://localhost:8000/docs`

## üìù API Endpoints

### 1. Health Check

```http
GET /health
```

**Response:**
```json
{
  "status": "healthy",
  "model": "loaded",
  "database": "connected",
  "cuda": {
    "available": true,
    "gpu": "NVIDIA GeForce RTX 3050 Ti Laptop GPU",
    "version": "12.1",
    "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"]
  }
}
```

### 2. Predict (`/api/v1/predict`)

D·ª± ƒëo√°n tin gi·∫£/th·∫≠t t·ª´ video TikTok.

**Request:**
```json
{
  "video_id": "1234567890",
  "video_url": "https://tiktok.com/@user/video/123",
  "caption": "Video caption text...",
  "ocr_text": "Text extracted from video frames...",
  "stt_text": "Transcribed audio text...",
  "author_id": "username"
}
```

**Response:**
```json
{
  "video_id": "1234567890",
  "prediction": "FAKE",
  "confidence": 0.85,
  "method": "rag_enhanced",
  "rag_used": true,
  "probabilities": {
    "REAL": 0.15,
    "FAKE": 0.85
  },
  "processing_time_ms": 1234.5
}
```

**Prediction Methods:**
- `cached`: K·∫øt qu·∫£ t·ª´ cache
- `base_model`: Ch·ªâ d√πng HAN model
- `rag_enhanced`: C√≥ s·ª≠ d·ª•ng RAG verification

### 3. Process Media (`/api/v1/process-media`)

X·ª≠ l√Ω media v·ªõi smart routing d·ª±a tr√™n URL type.

**Flow logic:**
- URL ch·ª©a `/video/` ‚Üí Ch·ªâ ch·∫°y **Whisper (STT)**
- URL ch·ª©a `/photo/` ‚Üí Ch·ªâ ch·∫°y **VietOCR**

**Request:**
```json
{
  "video_id": "1234567890",
  "video_url": "https://tiktok.com/@user/video/123"
}
```

**Response (Video):**
```json
{
  "video_id": "1234567890",
  "ocr_text": "",
  "stt_text": "Transcribed audio text...",
  "processing_time_ms": 3456.7
}
```

**Response (Photo):**
```json
{
  "video_id": "1234567890",
  "ocr_text": "Text extracted from images...",
  "stt_text": "",
  "processing_time_ms": 2345.6
}
```

### 4. Report (`/api/v1/report`)

B√°o c√°o k·∫øt qu·∫£ prediction sai.

**Request:**
```json
{
  "video_id": "1234567890",
  "reported_prediction": "FAKE",
  "reason": "Optional reason text..."
}
```

**Response:**
```json
{
  "status": "success",
  "message": "Report saved successfully"
}
```

### 5. Get Pending Reports (`/api/v1/reports/pending`)

L·∫•y danh s√°ch reports ƒëang ch·ªù review (admin).

**Query params:**
- `limit`: S·ªë l∆∞·ª£ng reports (default: 50)

## üîß Services Chi ti·∫øt

### Inference Service (`services/inference.py`)

**HANONNXInference Class:**
- Load ONNX model v·ªõi CUDA support
- Text normalization (Vietnamese)
- Chunk selection v·ªõi RAG
- Model prediction

**GPU Configuration:**
- ONNX Runtime: `CUDAExecutionProvider` (n·∫øu c√≥ CUDA)
- SentenceTransformer: `device='cuda'` (auto-detect)

**Methods:**
- `predict(title, content)`: D·ª± ƒëo√°n v·ªõi HAN model
- `_select_chunks_with_rag()`: Ch·ªçn chunks quan tr·ªçng

### RAG Service (`services/rag_service.py`)

**RAGService Class:**
- Vector similarity search (GPU)
- Verification v·ªõi news corpus
- Confidence adjustment

**GPU Configuration:**
- SentenceTransformer: `device='cuda'` (auto-detect)

**Methods:**
- `should_use_rag()`: Quy·∫øt ƒë·ªãnh c√≥ d√πng RAG kh√¥ng
- `verify_with_sources()`: T√¨m ki·∫øm v√† verify

**RAG Triggers:**
- High confidence (>0.95)
- Clickbait patterns
- Sensitive topics
- Breaking news keywords
- Unknown source v·ªõi high confidence

### Media Processor (`services/media_processor.py`)

**MediaProcessor Class:**
- Download video/image t·ª´ TikTok
- **Smart URL detection**: Detect `/video/` vs `/photo/`
- Extract frames cho OCR
- Extract audio cho STT

**Methods:**
- `detect_tiktok_type(url)`: Detect URL type
- `download_media()`: Download v·ªõi yt-dlp
- `extract_frames()`: Extract frames t·ª´ video
- `extract_audio()`: Extract audio track

### OCR Service (`services/ocr_service.py`)

**OCRService Class:**
- S·ª≠ d·ª•ng VietOCR (Vietnamese optimized)
- Extract text t·ª´ frames/images
- GPU support v·ªõi CUDA

**GPU Configuration:**
- Device: `cuda:0` (auto-detect)

**Methods:**
- `extract_text_from_frames()`: OCR t·ª´ video frames
- `extract_text_from_image()`: OCR t·ª´ image

### STT Service (`services/stt_service.py`)

**STTService Class:**
- S·ª≠ d·ª•ng OpenAI Whisper (`medium` model)
- Transcribe audio sang text
- GPU support v·ªõi CUDA

**GPU Configuration:**
- Model: `medium` (ti·∫øt ki·ªám VRAM)
- Device: `cuda` (auto-detect)

**Methods:**
- `transcribe_audio()`: Speech-to-Text

### Supabase Client (`services/supabase_client.py`)

**SupabaseService Class:**
- Database operations
- Vector search
- Caching

**Methods:**
- `get_video()`: L·∫•y cached prediction
- `save_video()`: L∆∞u prediction
- `search_similar_news()`: Vector similarity search
- `save_report()`: L∆∞u user report

## üñ•Ô∏è GPU Support

### CUDA Detection

Backend t·ª± ƒë·ªông detect CUDA khi kh·ªüi ƒë·ªông:
- Ki·ªÉm tra PyTorch CUDA availability
- Ki·ªÉm tra ONNX Runtime CUDA providers
- Log GPU information

### GPU Services

| Service | Device | Model |
|---------|--------|-------|
| **Whisper (STT)** | `cuda` | `medium` |
| **VietOCR** | `cuda:0` | `vgg_transformer` |
| **ONNX Model** | `CUDAExecutionProvider` | `han_rag_model.onnx` |
| **SentenceTransformer (inference)** | `cuda` | `keepitreal/vietnamese-sbert` |
| **SentenceTransformer (RAG)** | `cuda` | `keepitreal/vietnamese-sbert` |

### Fallback

N·∫øu kh√¥ng c√≥ CUDA, t·∫•t c·∫£ services t·ª± ƒë·ªông fallback v·ªÅ CPU.

## üß™ Testing

### Test v·ªõi curl

```bash
# Health check v·ªõi CUDA info
curl http://localhost:8000/health

# Predict
curl -X POST http://localhost:8000/api/v1/predict \
  -H "Content-Type: application/json" \
  -d '{
    "video_id": "test123",
    "video_url": "https://tiktok.com/@test/video/123",
    "caption": "Test caption"
  }'
```

### Test v·ªõi Python

```python
import requests

response = requests.post(
    "http://localhost:8000/api/v1/predict",
    json={
        "video_id": "test123",
        "video_url": "https://tiktok.com/@test/video/123",
        "caption": "Test caption"
    }
)
print(response.json())
```

## üìä Performance

### Benchmarks (v·ªõi GPU)

- **Prediction (no cache)**: ~1-3 gi√¢y
- **Prediction (cached)**: <100ms
- **Media processing**:
  - Video (STT): ~3-5 gi√¢y (GPU)
  - Photo (OCR): ~2-4 gi√¢y (GPU)
- **RAG search**: ~500ms-1s (GPU)

### Optimization

1. **GPU Acceleration**: T·∫•t c·∫£ ML services d√πng GPU
2. **Caching**: K·∫øt qu·∫£ ƒë∆∞·ª£c cache trong database
3. **Smart Routing**: Video ‚Üí STT, Photo ‚Üí OCR
4. **Async operations**: FastAPI async support
5. **Model optimization**: ONNX Runtime cho inference nhanh

## üêõ Troubleshooting

### CUDA kh√¥ng detect ƒë∆∞·ª£c

**V·∫•n ƒë·ªÅ:** `CUDA: ‚ùå CPU only` trong logs
- **Gi·∫£i ph√°p:** 
  - Ki·ªÉm tra NVIDIA driver: `nvidia-smi`
  - Ki·ªÉm tra PyTorch CUDA: `python -c "import torch; print(torch.cuda.is_available())"`
  - C√†i ƒë·∫∑t `onnxruntime-gpu` thay v√¨ `onnxruntime`

### Model kh√¥ng load

**V·∫•n ƒë·ªÅ:** `FileNotFoundError: Model not found`
- **Gi·∫£i ph√°p:** Ki·ªÉm tra `MODEL_PATH` trong `.env`

### Database connection failed

**V·∫•n ƒë·ªÅ:** `Supabase connection failed`
- **Gi·∫£i ph√°p:** Ki·ªÉm tra `SUPABASE_URL` v√† `SUPABASE_KEY`

### OCR/STT kh√¥ng ho·∫°t ƒë·ªông

**V·∫•n ƒë·ªÅ:** `VietOCR/Whisper not available`
- **Gi·∫£i ph√°p:** 
  - C√†i ƒë·∫∑t dependencies: `pip install vietocr openai-whisper`
  - Ki·ªÉm tra FFmpeg ƒë√£ c√†i ƒë·∫∑t

### Memory issues (GPU)

**V·∫•n ƒë·ªÅ:** Out of memory khi process media
- **Gi·∫£i ph√°p:**
  - Services ch·∫°y tu·∫ßn t·ª± n√™n kh√¥ng lo h·∫øt VRAM
  - N·∫øu v·∫´n l·ªói, c√≥ th·ªÉ gi·∫£m model size (Whisper: `medium` ‚Üí `base`)

## üîí Security

- **CORS**: Configured cho extension origin
- **Input validation**: Pydantic models
- **SQL injection**: Supabase client t·ª± ƒë·ªông escape
- **RLS**: Row Level Security tr√™n database

## üìà Monitoring

### Logging

Server s·ª≠ d·ª•ng Python logging:
- Level: INFO
- Format: Timestamp, level, message
- Output: Console
- CUDA info ƒë∆∞·ª£c log khi kh·ªüi ƒë·ªông

### Metrics (c√≥ th·ªÉ th√™m)

- Request count
- Response time
- Error rate
- Cache hit rate
- GPU utilization

## üîÆ Future Improvements

- [ ] WebSocket support cho real-time updates
- [ ] Batch prediction API
- [ ] Model versioning
- [ ] A/B testing framework
- [ ] Prometheus metrics
- [ ] Distributed caching (Redis)
- [ ] Multi-GPU support

## üìÑ License

MIT License
